{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INPUT_TO_BERT.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMd6CgeTh8qADq1RhDip9yh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishabh9898/NLP/blob/master/INPUT_TO_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "q0euvsXRzCee"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CKXS7R4-y7BE"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cpzQkqaUzLGu"
      },
      "source": [
        "\n",
        "MODELS = [(BertModel, BertTokenizer, 'bert-base-uncased')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnt0-4y8zOhy"
      },
      "source": [
        "Using bert-base uncased model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V6XACS2zc_W"
      },
      "source": [
        "# LOADING OUR BERT MODEL AND TOKENIZER FROM IN-BUILT BERT \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UUuoJncUzOCE",
        "outputId": "e9687e16-86f9-4fad-80a3-b7b93447d07a"
      },
      "source": [
        "for model_class, tokenizer_class, pretrained_weights in MODELS:\n",
        "    \n",
        "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "    bert_model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYsG3TINzu3z"
      },
      "source": [
        "# READING OUR SST-2 SENTIMENT BANK DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sR7SY0cFzptU"
      },
      "source": [
        "\n",
        "df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOrXlGmbz-aI"
      },
      "source": [
        "# USING 4000 SENTENCES FOR FASTER PROCESS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pJZ_yGeqz6pl"
      },
      "source": [
        "\n",
        "batch = df[:2000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma46bsj00INs"
      },
      "source": [
        "# TOKENIZING AND PADDING OUR DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Fh1pywG_0ELt"
      },
      "source": [
        "def tokenize_cut_pad(df):\n",
        "    \n",
        "    df = df.copy()\n",
        "    \n",
        "    max_input_size = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
        "    \n",
        "    # shorten sequences longer than BERT max input size\n",
        "    df[0] = [text[:max_input_size - 2] for text in df[0].values] \n",
        "    tokenized = df[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True))) # tokenizes and converts tokens to ids, includes special tokens\n",
        "    \n",
        "    max_len = 0\n",
        "    for i in tokenized.values:\n",
        "        if len(i) > max_len:\n",
        "            # max_len will be equal to longest sequence in the tokenized values\n",
        "            max_len = len(i)\n",
        "\n",
        "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
        "    \n",
        "    return torch.tensor(padded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhMflhFV0cep"
      },
      "source": [
        "# Get BERT model embedding for each CLS token in each example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8WOZPfoE0cN2"
      },
      "source": [
        "input_ids = tokenize_cut_pad(batch)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nSe2w6iT0t6Y"
      },
      "source": [
        "with torch.no_grad():\n",
        "    last_hidden_states = bert_model(input_ids)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4VWbxbS4ShZ"
      },
      "source": [
        "# STORING LAST_HIDDEN_STATE IN VARIABLE FEATURES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yxzJThJM4O0g"
      },
      "source": [
        "features = last_hidden_states[:,0,:].numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PqkZ-0c4aGo"
      },
      "source": [
        "# STORING THE TEST SENTIMENT WHETHER 0 OR 1 IN LABELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-A_lnyUA4pkz"
      },
      "source": [
        "\n",
        "labels = batch[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qJ37M0eO4uE8"
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CRvrQu25C0X"
      },
      "source": [
        "# DEFAULT SPLIT TO 75-25%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5OQXJPHD48su",
        "outputId": "6d9f8bd0-9ff1-462e-f148-8376876f1eb5"
      },
      "source": [
        "\n",
        "print(train_features.shape)\n",
        "print(test_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1500, 768)\n",
            "(500, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR-LW-3N5Iaf"
      },
      "source": [
        "# INITIALIZING OUR MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-HxDMS2a5OHL",
        "outputId": "f67010b2-8bb1-4dd8-ea90-d67c77dc4f81"
      },
      "source": [
        "\n",
        "model = LogisticRegression(solver='lbfgs')\n",
        "model.fit(train_features, train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo456vd_5SoH"
      },
      "source": [
        "# TESTING OUR MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAUqfG475WOY",
        "outputId": "2cf0a2ca-8cbf-4cba-b923-0a1dd573c994"
      },
      "source": [
        "model.score(test_features, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYdDzLka5dEo"
      },
      "source": [
        "# PREDICTION OF MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3gHQWDTT5hLb"
      },
      "source": [
        "def prediction(text,a):\n",
        "    \n",
        "    input_text = tokenizer.encode(text)\n",
        "    test_input_ids = torch.tensor(input_text)\n",
        "    test_input_ids = test_input_ids.unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        hidden_states = bert_model(test_input_ids)[0]\n",
        "    test_features = hidden_states[:, 0, :].numpy()\n",
        "    pred = model.predict(test_features)[0]\n",
        "    a = pred\n",
        "    if pred == 1:\n",
        "        return \"This is a positive statement\",a\n",
        "    else:\n",
        "        return \"This is a negative statement\",a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyUI4jAc5lmf"
      },
      "source": [
        "# INPUT SENTENCE FROM USER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYqC1c5J6RiF",
        "outputId": "758c8985-4aeb-4d0c-ec17-137d07387763"
      },
      "source": [
        "string = str(input()) \n",
        "\n",
        "t = 0.0\n",
        "\n",
        "score = model.score(test_features, test_labels)\n",
        "\n",
        "sentiment,pred = prediction(string,t)\n",
        "\n",
        "print(sentiment + \" \" + \" with sentiment label :\" + str(pred)+ \" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "don't be a karen\n",
            "This is a negative statement  with sentiment label :0 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}